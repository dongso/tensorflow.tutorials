{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST convolutional neural networks\n",
    "\n",
    "* Make a networks like LeNet5 structure with MNIST data\n",
    "* input pipeline: `tf.data`\n",
    "* `Eager execution`\n",
    "* `Functional API`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:07.653910Z",
     "start_time": "2019-02-27T13:56:05.640191Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:08.473098Z",
     "start_time": "2019-02-27T13:56:07.658396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape([-1, 28, 28, 1])\n",
    "train_data = train_data.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape([-1, 28, 28, 1])\n",
    "test_data = test_data.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:08.786495Z",
     "start_time": "2019-02-27T13:56:08.475342Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 219\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index][...,0])\n",
    "plt.colorbar()\n",
    "#plt.gca().grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`\n",
    "\n",
    "### input pipeline `tf.data.Dataset` and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(image, label):\n",
    "  label = tf.one_hot(label, depth=10)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:08.822383Z",
     "start_time": "2019-02-27T13:56:08.792299Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(219)\n",
    "batch_size = 32\n",
    "max_epochs = 1\n",
    "\n",
    "# for train\n",
    "N = len(train_data)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size = batch_size)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "* Use `tf.keras.layers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `tf.keras.Sequential()` API (01.mnist.LeNet5.ipynb)\n",
    "```python\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=[5, 5], padding='same', activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=[5, 5], padding='same', activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:08.856849Z",
     "start_time": "2019-02-27T13:56:08.837484Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(MNISTModel, self).__init__()\n",
    "    self.conv1 = layers.Conv2D(filters=32, kernel_size=[5, 5], padding='same', activation='relu')\n",
    "    self.pool1 = layers.MaxPool2D()\n",
    "    self.conv2 = layers.Conv2D(filters=64, kernel_size=[5, 5], padding='same', activation='relu')\n",
    "    self.pool2 = layers.MaxPool2D()\n",
    "    self.flatten = layers.Flatten()\n",
    "    self.dense1 = layers.Dense(units=1024, activation='relu')\n",
    "    self.dense2 = layers.Dense(units=10, activation='softmax')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    \"\"\"Run the model.\"\"\"\n",
    "    conv1 = self.conv1(inputs)\n",
    "    pool1 = self.pool1(conv1)\n",
    "    conv2 = self.conv2(pool1)\n",
    "    pool2 = self.pool2(conv2)\n",
    "    flatten = self.flatten(pool2)\n",
    "    dense1 = self.dense1(flatten)\n",
    "    logits = self.dense2(dense1)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:08.872807Z",
     "start_time": "2019-02-27T13:56:08.864949Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:09.035493Z",
     "start_time": "2019-02-27T13:56:08.882976Z"
    }
   },
   "outputs": [],
   "source": [
    "# without training, just inference a model in eager execution:\n",
    "for images, labels in train_dataset.take(1):\n",
    "  predictions = model(images[0:1])\n",
    "  print(\"Predictions: \", predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:09.045559Z",
     "start_time": "2019-02-27T13:56:09.038414Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "### Define loss and accuray functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc_object = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:56:09.054474Z",
     "start_time": "2019-02-27T13:56:09.048300Z"
    }
   },
   "outputs": [],
   "source": [
    "# use Adam optimizer \n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "\n",
    "# record loss and accuracy for every epoch\n",
    "mean_loss = tf.keras.metrics.Mean(\"loss\")\n",
    "mean_accuracy = tf.keras.metrics.Mean(\"accuracy\")\n",
    "\n",
    "# save loss and accuracy history for plot\n",
    "loss_history = []\n",
    "accuracy_history = [(0, 0.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T14:01:13.569448Z",
     "start_time": "2019-02-27T13:56:09.057795Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"start training!\")\n",
    "global_step = 0\n",
    "num_batches_per_epoch = int(N / batch_size)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  \n",
    "  for step, (images, labels) in enumerate(train_dataset):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "      predictions = model(images)\n",
    "      loss_value = loss_object(labels, predictions)\n",
    "      acc_value = acc_object(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    global_step += 1\n",
    "    \n",
    "    mean_loss(loss_value)\n",
    "    mean_accuracy(acc_value)\n",
    "    loss_history.append((global_step, mean_loss.result().numpy()))\n",
    "    \n",
    "    if global_step % 10 == 0:\n",
    "      clear_output(wait=True)\n",
    "      epochs = epoch + step / float(num_batches_per_epoch)\n",
    "      duration = time.time() - start_time\n",
    "      examples_per_sec = batch_size / float(duration) \n",
    "      print(\"epochs: {:.2f}, step: {}, loss: {:.3g}, accuracy: {:.4g}% ({:.2f} examples/sec; {:.4f} sec/batch)\".format(\n",
    "          epochs, global_step, mean_loss.result().numpy(), mean_accuracy.result().numpy()*100, examples_per_sec, duration))\n",
    "      \n",
    "  # save mean accuracy for plot\n",
    "  accuracy_history.append((global_step, mean_accuracy.result().numpy()))\n",
    "\n",
    "  # clear the history\n",
    "  mean_accuracy.reset_states()\n",
    "\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T14:01:14.370347Z",
     "start_time": "2019-02-27T14:01:13.574417Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(*zip(*loss_history), label='loss')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Loss value [cross entropy]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(*zip(*accuracy_history), 'bo', label='accuracy')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Accuracy value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a model\n",
    "\n",
    "### Test trained model\n",
    "\n",
    "* test accuracy: 0.9798 for 1 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T14:01:46.877941Z",
     "start_time": "2019-02-27T14:01:14.387598Z"
    }
   },
   "outputs": [],
   "source": [
    "for images, labels in test_dataset:\n",
    "  predictions = model(images)\n",
    "  acc_object(labels, predictions)\n",
    "  \n",
    "print(\"test accuracy: {:.4g}%\".format(acc_object.result() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T14:01:46.888086Z",
     "start_time": "2019-02-27T14:01:46.882334Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T14:01:49.042786Z",
     "start_time": "2019-02-27T14:01:46.891972Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "\n",
    "batch_xs = test_data[batch_index]\n",
    "batch_ys = test_labels[batch_index]\n",
    "y_pred_ = model(batch_xs)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred_)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  if np.argmax(py) == batch_ys[i]:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='blue')\n",
    "  else:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='red')\n",
    "  p.imshow(px.reshape(28, 28))\n",
    "  p.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
