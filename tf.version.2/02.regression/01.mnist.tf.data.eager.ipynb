{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST softmax with `tf.data`\n",
    "\n",
    "* Make a very simple networks which have just one layer. (No hidden layers)\n",
    "* input pipeline: `tf.data`\n",
    "* Eager execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pseudo Code\n",
    "\n",
    "```python\n",
    "for epoch in max_epochs: # 1 epoch: 모든 데이터(N)를 한번 학습 시켰을 때\n",
    "  for step in num_batches: # num_batches = int(data_size / batch_size)\n",
    "    1. sampling mini-batches with batch_size\n",
    "      1-1. data augmentation [if you need (actually always)]\n",
    "    2. calculate the logits # logits = f(x)\n",
    "    3. calculate the loss # loss = loss(logits, labels)\n",
    "    4. calculate the gradient with respect to weights\n",
    "    5. update weights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:14.733848Z",
     "start_time": "2019-02-27T12:59:12.937555Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:14.743734Z",
     "start_time": "2019-02-27T12:59:14.736937Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:15.522500Z",
     "start_time": "2019-02-27T12:59:14.746541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape(-1, 784)\n",
    "train_data = train_data.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape(-1, 784)\n",
    "test_data = test_data.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:15.798635Z",
     "start_time": "2019-02-27T12:59:15.526204Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 123\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28, 28))\n",
    "plt.colorbar()\n",
    "#plt.gca().grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`\n",
    "\n",
    "### input pipeline `tf.data.Dataset` and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:15.829317Z",
     "start_time": "2019-02-27T12:59:15.803894Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(219)\n",
    "batch_size = 32\n",
    "max_epochs = 10\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.batch(batch_size = batch_size)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "* Use `tf.keras.layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:15.843949Z",
     "start_time": "2019-02-27T12:59:15.835288Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "#layers.Dense(64, activation='relu'),\n",
    "# Add another:\n",
    "#layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "#layers.Dense(10)])\n",
    "layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:15.933354Z",
     "start_time": "2019-02-27T12:59:15.848109Z"
    }
   },
   "outputs": [],
   "source": [
    "# without training, just inference a model in eager execution:\n",
    "for images, labels in train_dataset.take(1):\n",
    "  print(\"Logits: \", model(images[0:1]).numpy())\n",
    "  logits = model(images, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:15.944542Z",
     "start_time": "2019-02-27T12:59:15.936236Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "### Define a optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T12:59:15.956826Z",
     "start_time": "2019-02-27T12:59:15.952587Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:00:04.297427Z",
     "start_time": "2019-02-27T12:59:15.960149Z"
    }
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "for epoch in range(max_epochs):\n",
    "  for (step, (images, labels)) in enumerate(train_dataset):\n",
    "    start_time = time.time()\n",
    "    with tf.GradientTape() as tape:\n",
    "      logits = model(images, training=True)\n",
    "      loss_value = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "\n",
    "    loss_history.append(loss_value.numpy())\n",
    "    grads = tape.gradient(loss_value, model.variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                              global_step=global_step)\n",
    "\n",
    "    if global_step.numpy() % 100 == 0:\n",
    "      clear_output(wait=True)\n",
    "      duration = time.time() - start_time\n",
    "      examples_per_sec = batch_size / float(duration)\n",
    "      epochs = batch_size * global_step.numpy() / float(len(train_data))\n",
    "      print(\"epochs: {:.2f}, step: {}, loss: {:g}, ({:.2f} examples/sec; {:.3f} sec/batch)\".format(epochs, global_step.numpy(), loss_value, examples_per_sec, duration))\n",
    "\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:00:04.570468Z",
     "start_time": "2019-02-27T13:00:04.299486Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_history, label='loss')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Loss value [cross entropy]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a model\n",
    "\n",
    "### Test trained model\n",
    "\n",
    "* test accuracy: 0.9112 for 1 epochs\n",
    "* test accuracy: 0.9277 for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:00:11.593736Z",
     "start_time": "2019-02-27T13:00:04.573011Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = tf.contrib.eager.metrics.Accuracy()\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "  logits = model(images, training=False)\n",
    "  accuracy(labels=labels, predictions=tf.cast(tf.argmax(logits, 1), tf.int32))\n",
    "  \n",
    "print(\"test accuracy: {}\".format(accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:00:11.601652Z",
     "start_time": "2019-02-27T13:00:11.596536Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:00:12.667862Z",
     "start_time": "2019-02-27T13:00:11.605134Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "\n",
    "batch_xs = test_data[batch_index]\n",
    "batch_ys = test_labels[batch_index]\n",
    "y_pred_ = model(batch_xs, training=False)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred_)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  if np.argmax(py) == batch_ys[i]:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='blue')\n",
    "  else:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='red')\n",
    "  p.imshow(px.reshape(28, 28))\n",
    "  p.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
