{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST softmax with `tf.data`\n",
    "\n",
    "* Make a very simple networks which have just one layer. (No hidden layers)\n",
    "* input pipeline: `tf.data`\n",
    "* Eager execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pseudo Code\n",
    "\n",
    "```python\n",
    "for epoch in max_epochs: # 1 epoch: 모든 데이터(N)를 한번 학습 시켰을 때\n",
    "  for step in num_batches: # num_batches = int(data_size / batch_size)\n",
    "    1. sampling mini-batches with batch_size\n",
    "      1-1. data augmentation [if you need (actually always)]\n",
    "    2. calculate the predictions # predictions = f(x)\n",
    "    3. calculate the loss # loss = loss(labels, predictions)\n",
    "    4. calculate the gradient with respect to weights\n",
    "    5. update weights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:50:09.386388Z",
     "start_time": "2019-03-11T06:50:07.756789Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:50:09.409839Z",
     "start_time": "2019-03-11T06:50:09.398159Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:50:10.971805Z",
     "start_time": "2019-03-11T06:50:10.202174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape(-1, 784)\n",
    "train_data = train_data.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape(-1, 784)\n",
    "test_data = test_data.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:50:12.516972Z",
     "start_time": "2019-03-11T06:50:12.314191Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 1234\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28, 28))\n",
    "plt.colorbar()\n",
    "#plt.gca().grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "* Use `tf.keras.layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:50:13.169781Z",
     "start_time": "2019-03-11T06:50:13.146599Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:01:35.724742Z",
     "start_time": "2019-02-27T13:01:35.721465Z"
    }
   },
   "source": [
    "### Compile a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:50:17.750494Z",
     "start_time": "2019-03-11T06:50:17.740962Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without training, just inference a model in eager execution:\n",
    "predictions = model(train_data[0:1], training=False)\n",
    "print(\"Predictions: \", predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:50:26.807140Z",
     "start_time": "2019-03-11T06:50:26.803762Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "### Using `model.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:51:01.958859Z",
     "start_time": "2019-03-11T06:50:38.996084Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 10\n",
    "\n",
    "# using `numpy type` data\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    batch_size=batch_size, epochs=max_epochs,\n",
    "                    validation_split=0.05)\n",
    "# using `tf.data.Dataset`\n",
    "#history = model.fit(train_dataset, epochs=max_epochs,\n",
    "#                    steps_per_epoch=int(len(train_data) / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss funtion and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:51:03.948937Z",
     "start_time": "2019-03-11T06:51:03.941971Z"
    }
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:51:12.686509Z",
     "start_time": "2019-03-11T06:51:12.363440Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(max_epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a model\n",
    "\n",
    "### Test trained model\n",
    "\n",
    "* Compare test accuracy for 1 epoch and 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:51:51.458065Z",
     "start_time": "2019-03-11T06:51:51.223058Z"
    }
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data, test_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:51:53.209509Z",
     "start_time": "2019-03-11T06:51:53.205148Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.3f}\".format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:33:19.292217Z",
     "start_time": "2019-02-27T13:33:19.288174Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T13:33:20.615446Z",
     "start_time": "2019-02-27T13:33:19.545969Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "\n",
    "batch_xs = test_data[batch_index]\n",
    "batch_ys = test_labels[batch_index]\n",
    "y_pred_ = model(batch_xs, training=False)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred_)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  if np.argmax(py) == batch_ys[i]:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='blue')\n",
    "  else:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='red')\n",
    "  p.imshow(px.reshape(28, 28))\n",
    "  p.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
